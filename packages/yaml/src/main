/*!
 * Copyright (c) Aaron Delasy
 * Licensed under the MIT License
 */

import
  Node,
  NodeMap,
  NodeMapping,
  NodeScalar,
  NodeSeq,
  State,
  Token,
  TokenType
from "./types"
import Node_stringify from "./node"

export Node
export Node_stringify
export NodeMap
export NodeMapping
export NodeScalar
export NodeSeq

export obj YAML {
  content: str
  mut tokens: Token[]
  mut nodes: Node[]
  mut state: State

  fn hasNext (self: ref Self) bool {
    return self.state.pos < self.nodes.len
  }

  fn next (mut self: ref Self) Node {
    return self.nodes[self.state.pos++]
  }

  fn reset (mut self: ref Self) {
    self.state = State{}
  }

  fn stringify (self: ref Self) str {
    mut code := ""

    loop i := 0; i < self.nodes.len; i++ {
      code += Node_stringify(self.nodes[i])
    }

    return code
  }

  fn _hasNextTk (self: ref Self) bool {
    mut pos := self.state.pos
    tokensLen := self.tokens.len

    loop pos < tokensLen && self.tokens[pos].t == .Whitespace {
      pos++
    }

    return pos < tokensLen
  }

  fn _nextTk (mut self: ref Self) Token {
    tokensLen := self.tokens.len

    loop self.state.pos < tokensLen && self.tokens[self.state.pos].t == .Whitespace {
      self.state.pos++
    }

    return self.tokens[self.state.pos++]
  }

  fn _nextTkIndent (self: ref Self) int {
    loop self._nextTkIs(.EOL) {}

    mut indent := 0
    if !self._hasNextTk() { return indent }
    tk := self.tokens[self.state.pos]

    if tk.t == .Whitespace {
      tkValLen := tk.val.len

      loop i := 0; i < tkValLen && tk.val[i] == ' '; i++ {
        indent += 1
      }
    }

    return indent
  }

  fn _nextTkIs (mut self: ref Self, t: TokenType) bool {
    if !self._hasNextTk() { return false }
    pos := self.state.pos
    tk := self._nextTk()

    if tk.t == t {
      return true
    }

    self.state.pos = pos
    return false
  }

  fn _tokenize (mut self: ref Self) {
    textStopChars := [':', '-', '[', ']', '{', '}', ',']
    contentLen := self.content.len

    loop i := 0; i < contentLen; i++ {
      ch := self.content[i]

      if ch == ':' {
        self.tokens.push(Token{t: .Colon, val: ch.str()})
      } elif ch == '-' {
        self.tokens.push(Token{t: .Minus, val: ch.str()})
      } elif ch == '[' {
        self.tokens.push(Token{t: .LBrack, val: ch.str()})
      } elif ch == ']' {
        self.tokens.push(Token{t: .RBrack, val: ch.str()})
      } elif ch == '{' {
        self.tokens.push(Token{t: .LBrace, val: ch.str()})
      } elif ch == '}' {
        self.tokens.push(Token{t: .RBrace, val: ch.str()})
      } elif ch == ',' {
        self.tokens.push(Token{t: .Comma, val: ch.str()})
      } elif ch == '#' {
        loop i + 1 < contentLen && self.content[i + 1] != '\n' {
          i++
        }
      } elif ch == '\r' || ch == '\n' {
        startIdx := i

        if ch == '\r' && i + 1 < contentLen && self.content[i + 1] == '\n' {
          i++
        }

        self.tokens.push(Token{
          t: .EOL,
          val: self.content.slice(startIdx, i + 1)
        })
      } elif ch.isWhitespace {
        startIdx := i

        loop (
          i + 1 < contentLen &&
          self.content[i + 1].isWhitespace &&
          self.content[i + 1] != '\r' &&
          self.content[i + 1] != '\n'
        ) {
          i++
        }

        self.tokens.push(Token{
          t: .Whitespace,
          val: self.content.slice(startIdx, i + 1)
        })
      } else {
        startIdx := i

        loop i + 1 < contentLen {
          ch := self.content[i + 1]

          if ch.isWhitespace || textStopChars.contains(ch) {
            break
          }

          i++
        }

        self.tokens.push(Token{
          t: .Text,
          val: self.content.slice(startIdx, i + 1)
        })
      }
    }
  }

  fn _parse (mut self: ref Self, indent := 0) Node? {
    mut node: Node?
    tk := self._nextTk()

    if tk.t == .Minus {
      value := self._stringifyTill(.EOL)
      n: Node = NodeScalar{value: value.trim()}
      return n
    }

    if tk.t == .Text {
      key := tk.val + self._stringifyTill(.Colon)
      if !self._nextTkIs(.Colon) { return nil }
      value := self._stringifyTill(.EOL)
      keyNode: Node = NodeScalar{value: key.trim()}

      if !value.empty {
        valueNode: Node = NodeScalar{value: value.trim()}
        n: Node = NodeMapping{key: keyNode, value: valueNode}
        return n
      }

      nexTkIndent := self._nextTkIndent()
      mut mappings: NodeMapping[]
      mut nodes: Node[]
      mut mappingsOnly := true

      if nexTkIndent > indent {
        loop self._nextTkIndent() >= nexTkIndent {
          childNode := self._parse(nexTkIndent)

          if childNode != nil {
            actualChildNode := childNode
            nodes.push(actualChildNode)

            if actualChildNode is NodeMapping {
              mappings.push(actualChildNode)
            } else {
              mappingsOnly = false
            }
          }
        }
      }

      if nodes.empty {
        n: Node = NodeMapping{key: keyNode}
        return n
      } elif mappingsOnly {
        n1: Node = NodeMap{mappings: mappings}
        n2: Node = NodeMapping{key: keyNode, value: n1}
        return n2
      } else {
        n1: Node = NodeSeq{items: nodes}
        n2: Node = NodeMapping{key: keyNode, value: n1}
        return n2
      }
    }

    return nil
  }

  fn _stringifyTill (mut self: ref Self, t: TokenType) str {
    tokensLen := self.tokens.len
    mut result := ""

    loop ; self.state.pos < tokensLen; self.state.pos++ {
      if self.tokens[self.state.pos].t == t || self.tokens[self.state.pos].t == .EOL {
        break
      }

      tk := self.tokens[self.state.pos]
      result += tk.val
    }

    return result
  }
}

export fn parse (content: str) YAML {
  mut result := YAML{content: content}
  result._tokenize()
  loop result._hasNextTk() {
    node := result._parse()
    if node != nil { result.nodes.push(node) }
  }
  result.reset()
  return result
}
